{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a34656e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded .env: c:\\Kaggle-agent\\.env\n",
      "âœ… Setup and authentication complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    from dotenv import find_dotenv, load_dotenv  # type: ignore\n",
    "except ImportError as e:\n",
    "    raise RuntimeError(\n",
    "        \"python-dotenv is not installed. Install it with: pip install python-dotenv\"\n",
    "    ) from e\n",
    "\n",
    "# Try to load .env from the notebook's current working directory\n",
    "env_path = find_dotenv(filename=\".env\", usecwd=True)\n",
    "if env_path:\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"âœ… Loaded .env: {env_path}\")\n",
    "else:\n",
    "    # Still attempt default behavior (may load from other locations)\n",
    "    load_dotenv()\n",
    "    print(f\"âš ï¸  No .env found via find_dotenv(). CWD: {Path.cwd()}\")\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise RuntimeError(\n",
    "        \"Missing GOOGLE_API_KEY. Ensure your .env is in the current working directory \"\n",
    "        f\"({Path.cwd()}) and contains GOOGLE_API_KEY=... then restart the kernel and re-run this cell.\"\n",
    "    )\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "print(\"âœ… Setup and authentication complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc264f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict\n",
    "import json\n",
    "import requests\n",
    "import subprocess\n",
    "import time\n",
    "import uuid\n",
    "import warnings\n",
    "\n",
    "from google.adk.agents import Agent, LlmAgent\n",
    "from google.adk.apps.app import App, EventsCompactionConfig\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.sessions import DatabaseSessionService\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.tools.tool_context import ToolContext\n",
    "from google.genai import types\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.tools import google_search\n",
    "from google.adk.agents import ParallelAgent, SequentialAgent\n",
    "from google.adk.memory import InMemoryMemoryService\n",
    "from google.adk.tools import load_memory, preload_memory\n",
    "from google.adk.agents.remote_a2a_agent import (\n",
    "    RemoteA2aAgent,\n",
    "    AGENT_CARD_WELL_KNOWN_PATH,\n",
    ")\n",
    "from google.adk.a2a.utils.agent_to_a2a import to_a2a\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"âœ… ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4d3773",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_config=types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1, # Initial delay before first retry (in seconds)\n",
    "    http_status_codes=[429, 500, 503, 504] # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fd197d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_service = (\n",
    "    InMemoryMemoryService()\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aa39c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "# HELPER FUNCTION\n",
    "\n",
    "async def run_session(runner_instance: Runner, user_queries: list[str] | str, session_id: str = \"default\"):\n",
    "    \"\"\"Helper function to run queries in a session and display responses.\"\"\"\n",
    "    print(f\"\\n### Session: {session_id}\")\n",
    "\n",
    "    # Create or retrieve session\n",
    "    try:\n",
    "        session = await session_service.create_session(\n",
    "            app_name=APP_NAME, user_id=USER_ID, session_id=session_id\n",
    "        )\n",
    "    except:\n",
    "        session = await session_service.get_session(\n",
    "            app_name=APP_NAME, user_id=USER_ID, session_id=session_id\n",
    "        )\n",
    "\n",
    "    # Convert single query to list\n",
    "    if isinstance(user_queries, str):\n",
    "        user_queries = [user_queries]\n",
    "\n",
    "    # Process each query\n",
    "    for query in user_queries:\n",
    "        print(f\"\\nUser > {query}\")\n",
    "        query_content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
    "\n",
    "        # Stream agent response\n",
    "        async for event in runner_instance.run_async(\n",
    "            user_id=USER_ID, session_id=session.id, new_message=query_content\n",
    "        ):\n",
    "            if event.is_final_response() and event.content and event.content.parts:\n",
    "                text = event.content.parts[0].text\n",
    "                if text and text != \"None\":\n",
    "                    print(f\"Model: > {text}\")\n",
    "\n",
    "\n",
    "print(\"âœ… Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ff4d35",
   "metadata": {},
   "source": [
    "___________________                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d97b9a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent created\n"
     ]
    }
   ],
   "source": [
    "# ADD MEMORY TO AGENT\n",
    "\n",
    "# Define constants used throughout the notebook\n",
    "APP_NAME = \"MemoryDemoApp\"\n",
    "USER_ID = \"demo_user\"\n",
    "\n",
    "# Create agent\n",
    "user_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"MemoryDemoAgent\",\n",
    "    instruction=\"Answer user questions in simple words.\",\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "532d0994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent and Runner created with memory support!\n"
     ]
    }
   ],
   "source": [
    "# Create Session Service\n",
    "session_service = InMemorySessionService()  # Handles conversations\n",
    "\n",
    "# Create runner with BOTH services\n",
    "runner = Runner(\n",
    "    agent=user_agent,\n",
    "    app_name=\"MemoryDemoApp\",\n",
    "    session_service=session_service,\n",
    "    memory_service=memory_service,  # Memory service is now available!\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent and Runner created with memory support!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac4d2151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: conversation-01\n",
      "\n",
      "User > My favorite series is Stranger Things. Can you write a Haiku about it?\n",
      "Model: > Upside Down's dark pull,\n",
      "Friendship fights the monstrous threat,\n",
      "Lights flicker, they're brave.\n"
     ]
    }
   ],
   "source": [
    "# User tells agent about their favorite color\n",
    "await run_session(\n",
    "    runner,\n",
    "    \"My favorite series is Stranger Things. Can you write a Haiku about it?\",\n",
    "    \"conversation-01\",  # Session ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "626b5991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Session contains:\n",
      "  user: My favorite series is Stranger Things. Can you write a Haiku...\n",
      "  model: Upside Down's dark pull,\n",
      "Friendship fights the monstrous thr...\n"
     ]
    }
   ],
   "source": [
    "session = await session_service.get_session(\n",
    "    app_name=APP_NAME, user_id=USER_ID, session_id=\"conversation-01\"\n",
    ")\n",
    "\n",
    "# Let's see what's in the session\n",
    "print(\"ðŸ“ Session contains:\")\n",
    "for event in session.events:\n",
    "    text = (\n",
    "        event.content.parts[0].text[:60]\n",
    "        if event.content and event.content.parts\n",
    "        else \"(empty)\"\n",
    "    )\n",
    "    print(f\"  {event.content.role}: {text}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a1e8d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Session added to memory!\n"
     ]
    }
   ],
   "source": [
    "# This is the key method!\n",
    "session = await session_service.get_session(\n",
    "    app_name=APP_NAME, user_id=USER_ID, session_id=\"conversation-01\"\n",
    ")\n",
    "await memory_service.add_session_to_memory(session)\n",
    "\n",
    "print(\"âœ… Session added to memory!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c791017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent with load_memory tool created.\n"
     ]
    }
   ],
   "source": [
    "# RETRIEVING MEMORY \n",
    "\n",
    "# Create agent\n",
    "user_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"MemoryDemoAgent\",\n",
    "    instruction=\"Answer user questions in simple words. Use load_memory tool if you need to recall past conversations.\",\n",
    "    tools=[\n",
    "        load_memory\n",
    "    ],  # Agent now has access to Memory and can search it whenever it decides to!\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent with load_memory tool created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7376cee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: color-test\n",
      "\n",
      "User > What is my favorite series?\n",
      "Model: > I see that your favorite series is Stranger Things.\n"
     ]
    }
   ],
   "source": [
    "# Create a new runner with the updated agent\n",
    "runner = Runner(\n",
    "    agent=user_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service,\n",
    "    memory_service=memory_service,\n",
    ")\n",
    "\n",
    "await run_session(runner, \"What is my favorite series?\", \"color-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792f7440",
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_session(runner, \"My birthday is on December 15th.\", \"birthday-session-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e159b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually save the session to memory\n",
    "birthday_session = await session_service.get_session(\n",
    "    app_name=APP_NAME, user_id=USER_ID, session_id=\"birthday-session-01\"\n",
    ")\n",
    "\n",
    "await memory_service.add_session_to_memory(birthday_session)\n",
    "\n",
    "print(\"âœ… Birthday session saved to memory!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a0afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test retrieval in a NEW session\n",
    "await run_session(\n",
    "    runner, \"When is my favorite series?\", \"birthday-session-03\"  # Different session ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21cb98af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Search Results:\n",
      "  Found 2 relevant memories\n",
      "\n",
      "  [user]: My favorite series is Stranger Things. Can you write a Haiku about it?...\n",
      "  [MemoryDemoAgent]: Upside Down's dark pull,\n",
      "Friendship fights the monstrous threat,\n",
      "Lights flicker,...\n"
     ]
    }
   ],
   "source": [
    "# Search for series preferences\n",
    "search_response = await memory_service.search_memory(\n",
    "    app_name=APP_NAME, user_id=USER_ID, query=\"What is the user's favorite series?\"\n",
    ")\n",
    "\n",
    "print(\"ðŸ” Search Results:\")\n",
    "print(f\"  Found {len(search_response.memories)} relevant memories\")\n",
    "print()\n",
    "\n",
    "for memory in search_response.memories:\n",
    "    if memory.content and memory.content.parts:\n",
    "        text = memory.content.parts[0].text[:80]\n",
    "        print(f\"  [{memory.author}]: {text}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ebaa8",
   "metadata": {},
   "source": [
    "____________            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd0ce143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Callback created.\n"
     ]
    }
   ],
   "source": [
    "# AUTO SAVE TO MEMORY\n",
    "\n",
    "async def auto_save_to_memory(callback_context):\n",
    "    \"\"\"Automatically save session to memory after each agent turn.\"\"\"\n",
    "    await callback_context._invocation_context.memory_service.add_session_to_memory(\n",
    "        callback_context._invocation_context.session\n",
    "    )\n",
    "\n",
    "print(\"âœ… Callback created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5578b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_NAME = \"AutoMemoryApp\"\n",
    "USER_ID = \"demo_user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f89e3e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent created with LiteLLM and automatic memory saving!\n"
     ]
    }
   ],
   "source": [
    "import litellm\n",
    "\n",
    "litellm.set_verbose = False\n",
    "litellm.suppress_debug_info = True\n",
    "\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "from google.adk.agents import LlmAgent\n",
    "import os\n",
    "\n",
    "llm_model = LiteLlm(\n",
    "    model=\"openrouter/meta-llama/llama-3.3-70b-instruct:free\",\n",
    "    # model = \"openrouter/google/gemini-2.0-flash-exp:free\",\n",
    "    # model = \"openrouter/nousresearch/hermes-3-llama-3.1-405b:free\",\n",
    "    # model = \"openrouter/meta-llama/llama-3.2-3b-instruct:free\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    api_base=\"https://openrouter.ai/api/v1\",\n",
    ")\n",
    "\n",
    "# Agent with automatic memory saving\n",
    "auto_memory_agent = LlmAgent(\n",
    "    model=llm_model,\n",
    "    name=APP_NAME,\n",
    "    instruction=\"Answer user questions.\",\n",
    "    tools=[preload_memory],\n",
    "    after_agent_callback=auto_save_to_memory,\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent created with LiteLLM and automatic memory saving!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccac09b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Agent with automatic memory saving\n",
    "# auto_memory_agent = LlmAgent(\n",
    "#     model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "#     name=APP_NAME,\n",
    "#     instruction=\"Answer user questions.\",\n",
    "#     tools=[preload_memory],\n",
    "#     after_agent_callback=auto_save_to_memory,  # saves after each turn\n",
    "# )\n",
    "\n",
    "# print(\"âœ… Agent created with automatic memory saving!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ac26616",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_service = InMemorySessionService()  # Handles conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85265887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Runner created.\n"
     ]
    }
   ],
   "source": [
    "# Create a runner for the auto-save agent\n",
    "# This connects our automated agent to the session and memory services\n",
    "auto_runner = Runner(\n",
    "    agent=auto_memory_agent,  # Use the agent with callback + preload_memory\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service,  # Same services from Section 3\n",
    "    memory_service=memory_service,\n",
    ")\n",
    "\n",
    "print(\"âœ… Runner created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fc014df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: auto-save-test\n",
      "\n",
      "User > I got an offer from Brillar yesterday!\n",
      "Model: > Congratulations again on the job offer from Brillar. You had mentioned this yesterday, and I'm excited to hear that it's still on your mind. How are you feeling about the offer today? Have you had a chance to think it over and consider whether you'll be accepting it, or are you still weighing your options?\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Tell the agent about a gift (first conversation)\n",
    "# The callback will automatically save this to memory when the turn completes\n",
    "await run_session(\n",
    "    auto_runner,\n",
    "    \"I got an offer from Brillar yesterday!\",\n",
    "    \"auto-save-test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afd0f46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: auto-save-test\n",
      "\n",
      "User > My favourite color is blue!\n",
      "Model: > Blue is a wonderful color. I'll make sure to... well, not exactly \"remember\" it, since I don't retain information from previous conversations, but I'm happy to chat with you about it now! What do you like most about the color blue?\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Tell the agent about a gift (first conversation)\n",
    "# The callback will automatically save this to memory when the turn completes\n",
    "await run_session(\n",
    "    auto_runner,\n",
    "    \"My favourite color is blue!\",\n",
    "    \"auto-save-test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f69c1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: conversation-01\n",
      "\n",
      "User > My favorite series is Stranger Things. Can you write a Haiku about it?\n",
      "Model: > Here's a Haiku for Stranger Things:\n",
      "\n",
      "Upside Down darkness\n",
      "Eleven's powers shine bright\n",
      "Hawkins' strange delight\n"
     ]
    }
   ],
   "source": [
    "# # User tells agent about their favorite color\n",
    "# await run_session(\n",
    "#     auto_runner,\n",
    "#     \"My favorite series is Stranger Things. Can you write a Haiku about it?\",\n",
    "#     \"conversation-01\",  # Session ID\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dadccf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: auto-save-test-2\n",
      "\n",
      "User > Whats my favourite color?\n",
      "Model: > I don't have that information. As the AutoMemoryApp agent, I don't retain any information from previous conversations. Although you mentioned earlier that your favorite color is blue, I don't have the ability to recall that information since it was from a previous conversation. If you'd like to share it with me again, I'd be happy to chat with you about it!\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Ask about the gift in a NEW session (second conversation)\n",
    "# The agent should retrieve the memory using preload_memory and answer correctly\n",
    "await run_session(\n",
    "    auto_runner,\n",
    "    \"Whats my favourite color?\",\n",
    "    \"auto-save-test-2\",  # Different session ID - proves memory works across sessions!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9334a966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: auto-save-test-2\n",
      "\n",
      "User > where do i get the offer?\n",
      "Model: > You received the job offer from Brillar. You mentioned it in our previous conversation that you got the offer from them yesterday.\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Ask about the gift in a NEW session (second conversation)\n",
    "# The agent should retrieve the memory using preload_memory and answer correctly\n",
    "await run_session(\n",
    "    auto_runner,\n",
    "    \"where do i get the offer?\",\n",
    "    \"auto-save-test-2\",  # Different session ID - proves memory works across sessions!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a567e86",
   "metadata": {},
   "source": [
    "___________________________________________________________________     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b1f55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… tech_researcher created.\n"
     ]
    }
   ],
   "source": [
    "# Tech Researcher: Focuses on AI and ML trends.\n",
    "tech_researcher = Agent(\n",
    "    name=\"TechResearcher\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\n",
    "the main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"tech_research\",  # The result of this agent will be stored in the session state with this key.\n",
    ")\n",
    "\n",
    "print(\"âœ… tech_researcher created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8875e313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… health_researcher created.\n"
     ]
    }
   ],
   "source": [
    "# Health Researcher: Focuses on medical breakthroughs.\n",
    "health_researcher = Agent(\n",
    "    name=\"HealthResearcher\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\n",
    "their practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"health_research\",  # The result will be stored with this key.\n",
    ")\n",
    "\n",
    "print(\"âœ… health_researcher created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1150e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… finance_researcher created.\n"
     ]
    }
   ],
   "source": [
    "# Finance Researcher: Focuses on fintech trends.\n",
    "finance_researcher = Agent(\n",
    "    name=\"FinanceResearcher\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\n",
    "their market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"finance_research\",  # The result will be stored with this key.\n",
    ")\n",
    "\n",
    "print(\"âœ… finance_researcher created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a111b43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… aggregator_agent created with memory support!\n"
     ]
    }
   ],
   "source": [
    "# The AggregatorAgent runs *after* the parallel step to synthesize the results.\n",
    "# Added preload_memory tool and auto_save callback for memory integration\n",
    "aggregator_agent = LlmAgent(\n",
    "    name=\"AggregatorAgent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n",
    "    instruction=\"\"\"Combine these three research findings into a single executive summary:\n",
    "\n",
    "    **Technology Trends:**\n",
    "    {tech_research}\n",
    "    \n",
    "    **Health Breakthroughs:**\n",
    "    {health_research}\n",
    "    \n",
    "    **Finance Innovations:**\n",
    "    {finance_research}\n",
    "    \n",
    "    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\n",
    "    \n",
    "    You can also use preload_memory to recall any relevant past conversations or research.\"\"\",\n",
    "    tools=[preload_memory],  # Memory tool to access past conversations\n",
    "    after_agent_callback=auto_save_to_memory,  # Auto-save after completion\n",
    "    output_key=\"executive_summary\",  # This will be the final output of the entire system.\n",
    ")\n",
    "\n",
    "print(\"âœ… aggregator_agent created with memory support!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6162bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Parallel and Sequential Agents created.\n"
     ]
    }
   ],
   "source": [
    "# The ParallelAgent runs all its sub-agents simultaneously.\n",
    "parallel_research_team = ParallelAgent(\n",
    "    name=\"ParallelResearchTeam\",\n",
    "    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n",
    ")\n",
    "\n",
    "# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\n",
    "root_agent = SequentialAgent(\n",
    "    name=\"ResearchSystem\",\n",
    "    sub_agents=[parallel_research_team, aggregator_agent],\n",
    ")\n",
    "\n",
    "print(\"âœ… Parallel and Sequential Agents created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30037bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use full Runner with session and memory services (instead of InMemoryRunner)\n",
    "parallel_runner = Runner(\n",
    "    agent=root_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service,  # Reusing from memory section\n",
    "    memory_service=memory_service,    # Reusing from memory section\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a823a055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: default\n",
      "\n",
      "User > What did i get yesterday?parallel-research-session\n",
      "Model: > I cannot access personal information or past interactions, so I don't know what you received yesterday.\n",
      "\n",
      "If you are referring to a specific event or a piece of information, please provide more context, and I'll do my best to help. For instance, if you're asking about a Verizon credit for an outage, I can tell you that Verizon planned to issue a $20 credit to affected customers for an outage that occurred on Wednesday, January 15, 2026, with credits being sent via text and redeemable in the My Verizon app.\n",
      "Model: > Here are three key AI/ML trends for early 2026:\n",
      "\n",
      "1.  **Agentic AI and Autonomous Systems:** AI systems are increasingly designed to make decisions and perform complex, multi-step tasks independently, acting as digital collaborators. Major companies like Microsoft, Google, and AWS are developing frameworks for these autonomous agents. This shift promises significant productivity gains by automating complex workflows, but also raises questions about governance and security.\n",
      "\n",
      "2.  **Specialized and Compact AI Models:** While large language models (LLMs) continue to advance, there's a growing trend towards smaller, industry-specific models (SLMs) and highly efficient, compact models. Companies like NVIDIA and Google are developing specialized hardware (GPUs/TPUs) and optimization techniques to support these models. This development allows for more tailored AI solutions across sectors like healthcare and finance, while also addressing concerns about computational cost and energy consumption.\n",
      "\n",
      "3.  **AI Integration into Core Workflows and Development:** AI is moving beyond standalone tools to become deeply embedded in everyday business applications and software development lifecycles. This includes AI-native development platforms and tools that assist with coding, testing, and debugging. Major players like Microsoft (with Copilot) and Google are leading this integration. The impact is a significant acceleration of development cycles and increased productivity across various professional roles.\n",
      "Model: > Here are three significant recent medical breakthroughs:\n",
      "\n",
      "1.  **AI-Accelerated Drug Discovery**: Artificial intelligence (AI) is revolutionizing drug discovery by significantly reducing timelines, from years to months. Companies are using AI to identify drug targets, design molecules, and optimize compounds, leading to AI-designed drugs entering clinical trials. This is expected to become more integrated into pharmaceutical R&D by 2030.\n",
      "\n",
      "2.  **CRISPR Gene Editing in Therapeutics**: CRISPR technology is moving from the lab into clinical applications, with the first CRISPR therapies approved for conditions like sickle cell disease. It's being explored for treating genetic diseases, cancers, and other disorders, with numerous clinical trials underway. Widespread clinical integration is anticipated within the next decade.\n",
      "\n",
      "3.  **Advanced Alzheimer's Treatments**: New therapies targeting amyloid plaques, such as lecanemab, have shown promise in slowing cognitive decline. Research continues into novel biomarkers, combination therapies, and personalized medicine approaches. These advancements offer new hope, with ongoing research aiming to further refine and expand treatment options.\n",
      "Model: > I cannot tell you what you received yesterday as I do not have access to your personal information or past interactions.\n"
     ]
    }
   ],
   "source": [
    "# Run with the helper function that handles sessions properly\n",
    "await run_session(\n",
    "    parallel_runner,\n",
    "    \"Run the daily executive briefing on Tech, Health, and Finance\",\n",
    "    # \"What did i get yesterday?\"\n",
    "    \"parallel-research-session\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
